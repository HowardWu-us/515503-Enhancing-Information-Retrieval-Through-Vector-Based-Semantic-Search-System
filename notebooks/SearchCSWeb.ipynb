{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    article_url: str\n",
    "    original_title: str\n",
    "    translated_title: str\n",
    "    \n",
    "    def __init__(self, url: str, title: str) -> None:\n",
    "        self.article_url = url\n",
    "        self.original_title = title\n",
    "\n",
    "class ArticleCollection:\n",
    "    articles: list[Article]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.articles = []\n",
    "\n",
    "    def add_article(self, article: Article):\n",
    "        self.articles.append(article)\n",
    "\n",
    "    def info(self,):\n",
    "        print(f\"There are {len(self.articles)} titles.\")\n",
    "        \n",
    "    def display_titles(self):\n",
    "        for article in self.articles:\n",
    "            print(f\"Original Title: {article.original_title}\")\n",
    "            print(f\"URL: {article.article_url}\")\n",
    "            print(\"-\" * 15, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCollectionFromUrl(ArticleCollection):\n",
    "    urls: list[str] = []\n",
    "    def __init__(self, urls=[]):\n",
    "        self.urls = urls\n",
    "        super().__init__()\n",
    "\n",
    "    def fetch_articles(self,):\n",
    "        for url in tqdm(self.urls):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                for item in soup.find_all(\"li\", class_=\"announcement-item\"):\n",
    "                    link_tag = item.find(\"h2\").find(\"a\")\n",
    "                    title = link_tag.text.strip()\n",
    "                    href = link_tag[\"href\"]\n",
    "                    self.add_article(Article(url=href, title=title))\n",
    "            else:\n",
    "                print(f\"無法訪問網站，狀態碼：{response.status_code}\")\n",
    "        return len(self.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:02<00:00,  8.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 207 titles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PAGES = 20\n",
    "Articles = ArticleCollectionFromUrl()\n",
    "Articles.urls = [f\"https://www.cs.nycu.edu.tw/announcements?page={i}\" for i in range(1, PAGES+1)]\n",
    "\n",
    "Articles.fetch_articles()\n",
    "Articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate articles to English\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 207/207 [00:15<00:00, 13.50it/s]\n"
     ]
    }
   ],
   "source": [
    "from googletrans import Translator\n",
    "translator = Translator()\n",
    "# tn = translator.translate(\"【學士班】113學年度資工系學士班「畢業學分預審」作業公告(請於10/11前繳交)\", dest=\"en\").text\n",
    "# print(tn)\n",
    "print(\"Translate articles to English\")\n",
    "for i in tqdm(Articles.articles):\n",
    "    i.translated_title = translator.translate(i.original_title, dest=\"en\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/howard/Documents/Projects/Linear-Algebra-Final-Project/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading paraphrase-MiniLM-L6-v2...\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import numpy as np\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 預處理文本\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum()]# 移除標點\n",
    "    tokens = [word for word in tokens if word not in stop_words]# 除掉停用詞\n",
    "    return tokens\n",
    "\n",
    "class ArticleSearch:\n",
    "    def __init__(self, articles, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "        self.articles = articles\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.article_titles = [article.translated_title for article in articles]\n",
    "        self.article_vectors = self.model.encode(self.article_titles)\n",
    "\n",
    "    # 回傳前K個相似度最高的向量\n",
    "    def Kth_max(self, arr, k=1):\n",
    "        return np.argsort(-arr, axis=0)[:k]\n",
    "\n",
    "    def cosine_similarity_custom(self, A, B):\n",
    "        dot_product = np.dot(A, B)\n",
    "        norm_A = np.linalg.norm(A)\n",
    "        norm_B = np.linalg.norm(B)\n",
    "        return dot_product / (norm_A * norm_B)\n",
    "\n",
    "    def search(self, query):\n",
    "        query_vector = self.model.encode([query])\n",
    "        similarities = np.array([self.cosine_similarity_custom(query_vector, b)[0] for b in self.article_vectors])\n",
    "        return similarities\n",
    "\n",
    "    def get_suggestions(self, query, k=5):\n",
    "        similarities = self.search(query)\n",
    "        suggestions = self.Kth_max(similarities, k)\n",
    "        return suggestions, similarities\n",
    "\n",
    "    def print_suggestions(self, query, k=5):\n",
    "        suggestions, similarities = self.get_suggestions(query, k)\n",
    "        for index in suggestions:\n",
    "            print(f\"{index}\\t{similarities[index]:.4f} : {self.article_titles[index]}\")\n",
    "            print(f\"\\t\\t {self.articles[index].article_url}\")\n",
    "        print(f\"最相似的文章是: {self.article_titles[suggestions[0]]}\")\n",
    "print(\"loading paraphrase-MiniLM-L6-v2...\")\n",
    "article_search = ArticleSearch(Articles.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"AI競賽\"\n",
    "# article_search.print_suggestions(query, k=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # 用於驗證\n",
    "# for idx, i in enumerate(Articles.articles):\n",
    "#     if i.original_title.find(\"UIUC\") != -1:\n",
    "#         print(idx, i.original_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestCase:\n",
    "    query: str\n",
    "    target: str\n",
    "\n",
    "    def __init__(self, query, target):\n",
    "        self.query = query\n",
    "        self.target = target\n",
    "    \n",
    "    def find_target_index(self):\n",
    "        target_index: int\n",
    "        for idx, i in enumerate(Articles.articles):\n",
    "            if i.original_title.find(self.target) != -1:\n",
    "                # print(idx, i.original_title)\n",
    "                target_index = idx\n",
    "        return target_index\n",
    "\n",
    "    def get_score(self, article_search):\n",
    "        similarities = article_search.search(self.query)\n",
    "\n",
    "        target_idx = self.find_target_index()\n",
    "        most_similar_idx = article_search.Kth_max(similarities, k=10)\n",
    "        if np.where(most_similar_idx==target_idx)[0].size != 0:\n",
    "            return 10-np.where(most_similar_idx==target_idx)[0][0]\n",
    "        else:\n",
    "            return 0\n",
    "\n",
    "test_cases: list[TestCase] = [\n",
    "    TestCase(\"NVIDIA 研替\", \"NVIDIA 2025 研發替代役/實習開放職缺資訊\"),\n",
    "    TestCase(\"114甄試\", \"114學年度碩士班甄試入學第2階段備取生名單及報到注意事項\"),\n",
    "    TestCase(\"甄試名單\", \"114學年度碩士班甄試入學第1階段\"),\n",
    "    TestCase(\"AI競賽\", \"AI Junior Award 2025\"),\n",
    "    TestCase(\"書卷獎\", \"【學士班】112學年度第2學期書卷獎得獎名單公告\"),\n",
    "    TestCase(\"導師名單\", \"113.10.15更新【學士班】113學年度第一學期大學部導生名單\"),\n",
    "    TestCase(\"特殊選材\", \"114學年度資訊工程學系特殊選才招生公告\"),\n",
    "    TestCase(\"畢業學分\", \"【學士班】113學年度資工系學士班「畢業學分預審」作業公告(請於10/11前繳交)\"),\n",
    "    TestCase(\"校友 頒獎\", \"資訊人院刊- 資訊系友【交大日資工系友回娘家暨傑出系友頒獎典禮】\"),\n",
    "    TestCase(\"學士畢業\", \"【學士班】資訊工程學系畢業離系/離校作業公告\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def translate_test_query():\n",
    "    print(\"Translate TestCases to English...\")\n",
    "    for i in tqdm(test_cases):\n",
    "        i.query = translator.translate(text=i.query, dest=\"en\").text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = test_cases[-1].query\n",
    "# target = test_cases[-1].target\n",
    "# article_search.print_suggestions(query, k=10)\n",
    "# print(query)\n",
    "# print(target)\n",
    "# print(Articles.articles[test_cases[-1].find_target_index()].translated_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_target_index(target):\n",
    "#     target_index: int\n",
    "#     for idx, i in enumerate(Articles.articles):\n",
    "#         if i.original_title.find(target) != -1:\n",
    "#             target_index = idx\n",
    "#     return target_index\n",
    "# Articles.articles[find_target_index(\"AI Junior Award 2025\")].original_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def runtest():\n",
    "    translate_test_query()\n",
    "    scores = sum([i.get_score(article_search=article_search) for i in test_cases])/len(test_cases)\n",
    "    print(f\"score: {scores}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translate TestCases to English...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 10/10 [00:00<00:00, 11.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "score: 4.7\n"
     ]
    }
   ],
   "source": [
    "runtest()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[i.get_score(article_search=article_search) for i in test_cases]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "act: str = \"\"\n",
    "while True:\n",
    "    act = input(\"action: \")\n",
    "    if act == \"quit\":\n",
    "        break\n",
    "    if act == \"runtest\":\n",
    "        runtest()\n",
    "    if act == \"search\":\n",
    "        print(\"-\"*10)\n",
    "        query = input(\": \")\n",
    "        lang = translator.detect(query).lang\n",
    "        if query[:2] == \"ch\":\n",
    "            lang = \"ch\"\n",
    "            query = query[2:]\n",
    "        else:\n",
    "            lang = \"en\"\n",
    "\n",
    "        if lang == \"en\":\n",
    "            article_search.print_suggestions(query=query, k=5)\n",
    "        else:\n",
    "            print(\"translating...\")\n",
    "            translated_query = translator.translate(text=query, dest=\"en\").text\n",
    "            print(f\"->{translated_query}\")\n",
    "            article_search.print_suggestions(query=translated_query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!jupyter nbconvert --to script SearchCSWeb.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
