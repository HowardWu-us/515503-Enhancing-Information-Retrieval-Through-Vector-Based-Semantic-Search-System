{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Article:\n",
    "    article_url: str\n",
    "    original_title: str\n",
    "    \n",
    "    def __init__(self, url: str, title: str) -> None:\n",
    "        self.article_url = url\n",
    "        self.original_title = title\n",
    "\n",
    "class ArticleCollection:\n",
    "    articles: list[Article]\n",
    "\n",
    "    def __init__(self):\n",
    "        self.articles = []\n",
    "\n",
    "    def add_article(self, article: Article):\n",
    "        self.articles.append(article)\n",
    "\n",
    "    def info(self,):\n",
    "        print(f\"There are {len(self.articles)} titles.\")\n",
    "        \n",
    "    def display_titles(self):\n",
    "        for article in self.articles:\n",
    "            print(f\"Original Title: {article.original_title}\")\n",
    "            print(f\"URL: {article.article_url}\")\n",
    "            print(\"-\" * 15, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ArticleCollectionFromUrl(ArticleCollection):\n",
    "    urls: list[str] = []\n",
    "    def __init__(self, urls=[]):\n",
    "        self.urls = urls\n",
    "        super().__init__()\n",
    "\n",
    "    def fetch_articles(self,):\n",
    "        for url in tqdm(self.urls):\n",
    "            response = requests.get(url)\n",
    "            if response.status_code == 200:\n",
    "                soup = BeautifulSoup(response.text, \"html.parser\")\n",
    "                for item in soup.find_all(\"li\", class_=\"announcement-item\"):\n",
    "                    link_tag = item.find(\"h2\").find(\"a\")\n",
    "                    title = link_tag.text.strip()\n",
    "                    href = link_tag[\"href\"]\n",
    "                    self.add_article(Article(url=href, title=title))\n",
    "            else:\n",
    "                print(f\"無法訪問網站，狀態碼：{response.status_code}\")\n",
    "        return len(self.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 20/20 [00:01<00:00, 11.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 207 titles.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "PAGES = 20\n",
    "Articles = ArticleCollectionFromUrl()\n",
    "Articles.urls = [f\"https://www.cs.nycu.edu.tw/announcements?page={i}\" for i in range(1, PAGES+1)]\n",
    "\n",
    "Articles.fetch_articles()\n",
    "Articles.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "import numpy as np\n",
    "import nltk\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# 預處理文本\n",
    "def preprocess_text(text):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    tokens = [word for word in tokens if word.isalnum()]# 移除標點\n",
    "    tokens = [word for word in tokens if word not in stop_words]# 除掉停用詞\n",
    "    return tokens\n",
    "\n",
    "class ArticleSearch:\n",
    "    def __init__(self, articles, model_name='paraphrase-MiniLM-L6-v2'):\n",
    "        self.articles = articles\n",
    "        self.model = SentenceTransformer(model_name)\n",
    "        self.article_titles = [article.original_title for article in articles]\n",
    "        self.article_vectors = self.model.encode(self.article_titles)\n",
    "\n",
    "    # 回傳前K個相似度最高的向量\n",
    "    def Kth_max(self, arr, k=1):\n",
    "        return np.argsort(-arr, axis=0)[:k]\n",
    "\n",
    "    def cosine_similarity_custom(self, A, B):\n",
    "        dot_product = np.dot(A, B)\n",
    "        norm_A = np.linalg.norm(A)\n",
    "        norm_B = np.linalg.norm(B)\n",
    "        return dot_product / (norm_A * norm_B)\n",
    "\n",
    "    def search(self, query):\n",
    "        query_vector = self.model.encode([query])\n",
    "        similarities = np.array([self.cosine_similarity_custom(query_vector, b)[0] for b in self.article_vectors])\n",
    "        return similarities\n",
    "\n",
    "    def get_suggestions(self, query, k=5):\n",
    "        similarities = self.search(query)\n",
    "        suggestions = self.Kth_max(similarities, k)\n",
    "        return suggestions, similarities\n",
    "\n",
    "    def print_suggestions(self, query, k=5):\n",
    "        suggestions, similarities = self.get_suggestions(query, k)\n",
    "        for index in suggestions:\n",
    "            print(f\"{index}\\t{similarities[index]:.4f} : {self.article_titles[index]}\")\n",
    "        print(f\"最相似的文章是: {self.article_titles[suggestions[0]]}\")\n",
    "        \n",
    "article_search = ArticleSearch(Articles.articles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "156\t0.8431 : 財團法人福琳工商發展基金會工商學生清寒獎學金\n",
      "127\t0.8124 : 戴夫寇爾全國資訊安全獎學金計畫\n",
      "105\t0.7936 : 力積電獎學金及學/暑期實習說明會(報名至10/8 中午12:00截止)\n",
      "16\t0.7906 : 【趨勢科技-新鮮人擴大徵才】\n",
      "42\t0.7845 : 國泰儲備/海外人才實習說明\n",
      "最相似的文章是: 財團法人福琳工商發展基金會工商學生清寒獎學金\n"
     ]
    }
   ],
   "source": [
    "query = \"獎學金\"\n",
    "article_search.print_suggestions(query, k=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 用於驗證\n",
    "for idx, i in enumerate(Articles.articles):\n",
    "    if i.original_title.find(\"UIUC\") != -1:\n",
    "        print(idx, i.original_title)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
